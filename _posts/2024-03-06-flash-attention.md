---
layout: post
title: "Explained: Flash Attention"
tags: ai, deep-learning, flash-attention, kernel, cuda, machine-learning, explained, tutorial, thoughts
---

I gave a short presentation on Flash Attention, diving into the motivation, the implementation and the results.

Slides can be accessed [here](https://docs.google.com/presentation/d/1QABa0RjnAFQfFTxjO0tuhjwtTKFOjsbnSxv7uEAIkHE/edit?usp=sharing).